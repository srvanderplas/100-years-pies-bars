---
title: "100 years of Pies vs. Bars"
format:
  pdf:
    keep-tex: true
    documentclass: article
    papersize: letter
    fontsize: 10pt
    include-in-header:
      - text: |
          \usepackage{url}
          \usepackage{hyperref}
          \usepackage{latexsym}
          \usepackage{amsmath, amsthm, amsfonts}
          \usepackage[dvipsnames]{xcolor} % colors
          \newcommand{\mt}[1]{{\textcolor{blue}{#1}}}
          \newcommand{\svp}[1]{{\textcolor{RedOrange}{#1}}}
    mainfont: Times New Roman
    colorlinks: true
author:
   - name: Maksuda Aktar Toma
     affiliation:
       department: Statistics Department
       name: University of Nebraska, Lincoln
     email: mtoma2@huskers.unl.edu
     corresponding: true
   - name: Susan Vanderplas
     affiliation:
       department: Statistics Department
       name: University of Nebraska-Lincoln
     email: svanderplas2@unl.edu
     orcid: 0000-0002-3803-0972

bibliography: refs.bib
filters:
   - latex-environment
commands: [mt,svp]
editor: 
  markdown: 
    wrap: sentence
---

# Abstract

The debate between pie charts and bar charts has been ongoing for over a century.
<!-- Ok, the debate is not between the charts -- it's between either proponents of either chart (e.g. the people promoting them) or about the use of each chart.  -->
Numerous studies with distinct methodologies and experimental designs have attempted to 
determine which chart is more effective, but no single consensus has emerged, even after 100 years of experimentation.
In this paper, we assess the existing literature and attempt to reconcile experiments with diverging results.

It's really hard to reach in a conclusion that which one is better in just a one liner.
We will review previous work on this topic, analyze their experimental designs, compare different scenarios, and attempt to generalize findings based on these studies.

# Introduction

Although William Playfair is frequently acknowledged with popularizing pie and bar charts in the early 1800s, the earliest documented use of bar charts can be traced to the 14th century, when Nicole Oresme employed bar-like representations in The Latitude of Forms.  Consequently, Playfair's contribution is mostly in the formalization and distribution of these charts rather than their creation. By the turn of the 20th century, strong opinions about the effectiveness of different chart types—especially pies versus bars—were already appearing in textbooks and manuals.

For instance, @eellsRelativeMeritsCircles1926 quotes two contemporary resources that discuss pie charts as "not a desirable form of presentation" [@brintonGraphicMethodsPresenting1914] and, more strongly, "an insult to a man's intelligence" [@karsten1923charts].
@brintonGraphicMethodsPresenting1914 even identifies that the "sector method" is common, but if horizontal bar methods were used more frequently, they would be preferred for both speed and accuracy.
@eellsRelativeMeritsCircles1926 also quotes an excerpt from an introductory statistics textbook [@secristIntroductionStatisticalMethods1925], which argues that pie charts require more cognitive effort to use accurately than a comparable stacked bar chart, calling pie diagrams "clumsy and defective".
These insights mirror today's status quo: pie charts are stubbornly common, even though many design guidelines recommend against their use. Building on these early critiques, @wickhamGraphicalCriticismHistorical2013 observed that design guidelines anticipated later empirical findings across many visualization types.

@wickhamGraphicalCriticismHistorical2013 previously noted the prescience of design guidelines prior to empirical studies validating their recommendations across different types of visualizations. [Ok, can you connect this better to the previous paragraph somehow?]{.svp}

It's really hard to reach in a conclusion that which one is better in just a one liner.
We will review previous work on this topic, analyze their experimental designs, compare different scenarios, and attempt to generalize findings based on these studies.


# Motivation

Choosing the most effective chart type is crucial for accurately conveying quantitative information. Decades of research in graphical perception have shown that bar charts outperform pie charts in terms of accuracy, efficiency, and ease of interpretation @clevelandGraphicalPerceptionTheory1984; @spenceDisplayingProportionsPercentages1991. Despite this, pie charts remain prevalent in media, business, and education. Understanding why this mismatch persists — and how preferences or traditions shape visualization choices — is important for improving data literacy and promoting evidence-based design @skau2016arcs; @few2007pies. This study revisits 100 years of pie and bar chart usage to uncover trends in effectiveness, preference, and pedagogical shifts.

# The Dawn of Empirical Graphics

Interestingly, the question of pies and bars motivated some of the first empirical evaluations of charts, published in the Journal of the American Statistical Association: @eellsRelativeMeritsCircles1926, @vonhuhnFurtherStudiesGraphic1927, and @croxtonBarChartsCircle1927.
Experimenters approached the problem head-on, directly asking participants to estimate quantities from charts, and evaluated participants on accuracy and, in some cases, speed.
While more sophisticated testing methodologies have been developed over the past century [@vanderplasTestingStatisticalCharts2020], studies are still conducted today using direct estimation approaches [@vanderplasFramedReproducingRevisiting2019].
The phrasing of direct estimation questions is of primary importance: a simple mathematical transformation of the estimated quantity can have an outsized effect on the results. [One important insight from both historical and modern work is that the phrasing of the estimation task itself can strongly influence performance.
For instance, @croxtonBarChartsCircle1927 asked participants to "estimate what percentage each sector represented," whereas @eellsRelativeMeritsCircles1926 phrased his question more generally, asking participants to “judge the relative size of the sectors.” (See Figure 1 for a visual comparison.) These subtle differences in wording can lead to significantly different error rates—underscoring how critical question design is in graphical perception research.]{.mt}

::: {.center}

\begin{figure}[ht]
\centering
\begin{minipage}{0.32\textwidth}
  \includegraphics[width=\linewidth]{eells-1.png}
\end{minipage}
\begin{minipage}{0.32\textwidth}
  \includegraphics[width=\linewidth]{eells-2.png}
\end{minipage}
\begin{minipage}{0.32\textwidth}
  \includegraphics[width=\linewidth]{crox.png}
\end{minipage}
\caption{Sample stimuli from Eells (1926), where participants were asked to estimate proportions directly from unlabeled pie charts.Diagrams from Croxton (1927), using labeled segments to compare accuracy in circle and bar comparisons*}
\end{figure}

:::

[You might want to demonstrate this with an example, perhaps showing the phrasing of Croxton's study vs. Eells? You could even include screenshots from the papers.]{.svp}

The initial studies of the question of pies and bars failed to identify a clear "best chart" across all situations or even to clearly identify in which situations pie charts or bar charts should be preferred.
@eellsRelativeMeritsCircles1926 found that pie charts were read as accurately as bar charts and with comparable speed.
The simplified nature of the experiment attracted critiques from @vonhuhnFurtherStudiesGraphic1927; attached to these criticisms is a short study previously run by Croxton, which examined estimates of the ratio between smaller and larger sectors of two-category pie and bar charts; these contributions will be addressed separately even though they are often cited as a single paper, even within the JASA records.
@vonhuhnFurtherStudiesGraphic1927's paper provides several examples which highlight concerns with the Eells study, and argues that while pie charts may be better in certain simple situations, bar charts are much more extensible and facilitate more advanced comparisons, but does not include any experimental studies.
<!-- Not much has changed today - experimental work is often criticized by those who provide toy examples but no empirical data due to compromises necessary to ensure experimental control.  --> Croxton's early experimental data (attached to @vonhuhnFurtherStudiesGraphic1927) had a larger number of participants than @eellsRelativeMeritsCircles1926, but only tested two-category charts with only two proportions: .25 and .4.
In addition, Croxton's study elicited estimates from participants as $A/B$ comparisons, where $A + B = 1$, while Eells elicited estimates for $A$ and $B$ separately.
<!-- It seems that prior to @eellsRelativeMeritsCircles1926, some researchers were empirically testing charts, but these experiments were not necessarily published for broader consumption; when the conversation arose in JASA, Croxton had data from years prior ready to provide additional insight. --> 
This multi-year back-and-forth conversation is interesting in part because it pinpoints an early example of experimental statistical graphics as a discipline of interest to statisticians for both personal investigation and as an audience for the results.
[It is both an example of early graphical testing and a cautionary tale, as proponents of different viewpoints were primarily talking past each other. While the riposte in these early papers and the strong opinions in contemporary design guidelines are entertaining to read, they do not generally support informed choices about what chart to use in practice.]{.svp}

Subsequently, @croxtonBarChartsCircle1927 published additional data assessing the accuracy of estimates from pie and bar charts, varying number of categories, and orientation/alignment of sections.
@croxtonBarChartsCircle1927 found that pie charts matched or surpassed bar charts in most situations, across different scale alignments, and in charts with up to 5 categories (though differences were not statistically significant at 5 categories).
The final paper in this early set of comparisons was @croxtonGraphicComparisonsBars1932, which examined a variety of representations of proportional data, but outside the context of a statistical chart; the experimental stimuli, while applicable to charts, show a focus on general perception (though published in JASA).
Experimental graphics studies have largely gone unreported (if they were conducted) between 1932 and the 1980s, particularly in statistical publications, though the issue of pies and bars occasionally pops up during this period in other disciplines.
[However, guidance to favor bar charts over pie charts still shows up in statistical literature [@haemerPresentationProblemsSuiting1949;@haemerPseudoThirdDimension1951;@fienbergGraphicalMethodsStatistics1979;@nisselson1978graphic;@wickhamGraphicalCriticismHistorical2013]. It almost seems like approximately once a generation, statisticians think about graphics, decry the state of the field, and call for a better set of empirical guidelines.]{.svp}

# Modern Experimental Graphics
Approximately 55 years after the original sequence of experiments, @clevelandGraphicalPerceptionTheory1984, a statistician and a psychologist by training, respectively, conducted experiments on simple graphical elements.
These experiments were presented as supporting a hierarchy of graphical perception that evolved over the course of the study sequence.
This ranking indicates that aligned length judgments are more accurate than judgments based on area or angle, implying that bar charts are more accurately perceived than pie charts.
While the full hierarchy of feature comprehension is often assumed to be experimentally derived, the experiments presented in the series of Cleveland & McGill papers only inform a few elements of this hierarchy.
As in the late 1920s, the combination of introspection based reasoning and a sequence of simple experiments did not go uncontested.
@spenceDisplayingProportionsPercentages1991 (both psychologists) used forced-choice questions of the form "which is bigger, A or B+C" to investigate the accuracy of pie and bar charts for making part-to-whole comparisons.
The later studies show that the 1980-1990s experiments were more of an interdisciplinary conversation around data displays, [reflecting the fact that statistical graphics had]{.svp} become a [more]{.svp} general [scientific]{.svp} tool [and were no longer]{.svp} limited to statisticians.
As a result, the literature becomes fragmented; studies are conducted across different disciplines, with different methods, elicitation questions, protocols, and, ultimately, different conclusions.

![Different methods used to assess accuracy of pie chart estimates. In addition to the different ways to divide up a pie chart's comparisons, there are also different numerical quantities which can be requested: the ratio of C to A + B and the ratio of C to the whole (A + B + C). These different elicitation methods impact the accuracy of participant responses for each type of chart.](pie-slices.png){fig-alt="Three pie charts, divided up in A/B, (A/B)/C, and A/(B/C)/D slices. The first compares A to B, the second compares A+B to C, and the third compares A+D to B+C. Slices that are grouped (A/B) and (A/D), (B/C) are colored similarly."}

# Experimental design

## Experiment Description

This research synthesizes findings from a series of historical and modern experiments comparing pie and bar charts for interpreting proportional data.
Early studies, such as @eellsRelativeMeritsCircles1926 and @croxtonBarChartsCircle1927, focused on accuracy and speed in estimating single or dual category proportions (e.g., $A/B$ or $A / (A + B)$).
These experiments typically involved participants identifying which portion of a chart was larger or estimating ratios between segments.

@eellsRelativeMeritsCircles1926 designed a study to objectively assess the accuracy of pie versus bar charts for representing proportions.
Psychology students at Whitman College (n = 97) were first shown a page containing 15 subdivided pie charts, each representing 100%.
Students were asked to write their best estimate of the percentage represented by each sector, using whole numbers only and avoiding any measuring tools.

Three days later, the same students were given an equivalent set of bar charts showing the same proportions, and were again asked to estimate the percentages for each section.
The design intentionally favored the bars (common alignment of bar bases) to test whether any advantage of the pie chart could still be observed.
After completing the estimation tasks, participants reported the mental strategy they used (area, angle, arc length, or chord), and indicated which chart type they preferred.

[Eells (1926) did not ask participants to simply identify which segment was larger. Instead, it was a proportion estimation task—participants were asked to write down the percentage each segment represented of the whole ( A / (A + B + ...)), not to make a binary comparison (A vs B). The “which is larger” comparison task appears in later studies, such as @croxtonBarChartsCircle1927 and @spenceDisplayingProportionsPercentages1991]{.mt}

The large-scale study of @croxtonBarChartsCircle1927 aimed to determine which chart type---bar or circle---enabled more accurate estimation of component percentages.
A total of 807 participants evaluated 27 charts, each depicting known part-to-whole proportions.
For each percentage combination (ranging from 2 to 5 parts), one bar chart and one pie chart were created, yielding 13 matched pairs.
Each chart was shown individually (without any numerical scale), and participants were instructed to numerically estimate the percentage value of each segment---not simply identify which was larger.
This distinction is important that like @eellsRelativeMeritsCircles1926 , this was a proportion estimation task ( "What percent is this segment?"), not a comparison task ("Which is larger, A>B?").
Tasks requiring direct identification of the larger part appear in later studies, such as @spenceDisplayingProportionsPercentages1991 Each chart was printed on a large 22×28 inch card and shown one at a time in a randomized sequence to reduce bias.
Some pie charts were repeated with slice positions altered (25% at 1:30 vs. 6:00 orientation) to test whether visual alignment influenced judgment accuracy.
Unlike Eells, this study focused exclusively on accuracy, and results showed that while bar charts outperformed in a few specific conditions, pie charts generally led to more accurate estimates, especially with equal or near-equal slices and in multi-part configurations.

In response to Eells' earlier work, @vonhuhnFurtherStudiesGraphic1927 ran his own large-scale experiment to see whether bar charts or pie charts made it easier for people to compare ratios between parts---like "A is to B as 1 is to what?" Instead of estimating percentages of a whole, participants were directly comparing how much bigger or smaller one part was than another.
A total of 287 observers were shown two sets of matched charts: one set illustrated a 1:11 ratio, and another showed a 1:4 ratio, with each ratio presented once as a bar chart and once as a pie chart.
No scales or labels were used, and the chart order was controlled to avoid bias.
The key measure was accuracy---how close participants' estimates were to the actual ratios.
Results showed that bar charts led to more correct judgments in both cases, especially with the more extreme 1:11 ratio.
While pie charts performed slightly better in one metric, bar charts were clearly more consistent overall.
Unlike Eells' percentage-based task, this was a direct comparison task (A vs. B), and the study focused purely on accuracy---not speed or preference.

[In which experiment did they have to only identify which part of the chart was larger??]{.svp}

Modern experiments, such as @spenceDisplayingProportionsPercentages1991, expanded the task complexity by asking participants to compare single components (A vs. B), a component against a pair (A vs. B + C), and two pairs (A + B vs. C + D).These tasks were tested across multiple formats (pie, bar, and table), with variations in exposure time, number of components, and use of color or ordering.
Performance was evaluated in terms of speed and accuracy, allowing researchers to assess how perceptual and cognitive demands shift across visualization types and task difficulty.

@peterson1954accurately evaluated the accuracy of proportion estimation across eight common chart types used to represent parts of a whole: circle, disc, single bar, multiple bar, multiple cylinder, multiple square column, multiple area column, and partial cosmograph.
Each chart displayed five fixed proportions (43%, 23%, 18%, 10%, 6%) and was presented alongside a similar "decoy" graph to mask repetition.
A total of 112 U.S.
Air Force personnel viewed the charts in random order and estimated the percentage values for each component.
After discarding incomplete responses, 86 participants contributed 3,440 data points, forming the basis for comparison across visual formats.

[@clevelandGraphicalPerceptionTheory1984; -@clevelandGraphicalPerceptionGraphical1985] conducted a series of experiments to test a theory of graphical perception based on "elementary perceptual tasks" such as position, length, angle, area, and shading.
They hypothesized a hierarchy of these tasks based on how accurately people extract quantitative information from them.
In their experiments, participants viewed a range of common graph types---including bar charts, pie charts, and divided bar charts---and were asked to make visual judgments of values or differences.
The results supported their theory: judgments involving position along a common scale were the most accurate, followed by length, with angle (used in pie charts) yielding the least accurate responses.
These findings laid the foundation for many modern principles in data visualization design.

@clevelandExperimentGraphicalPerception1986 conducted a follow-up experiment to evaluate the accuracy of seven basic graphical perception tasks: position (aligned and non-aligned), length, angle, slope, and area (circle and blob).
Participants were shown visual stimuli in which one object served as a standard, and three comparison objects were judged as percentages relative to it.
Each participant made 210 judgments across 70 displays.
The study included 127 participants from diverse educational backgrounds.
Results confirmed a perceptual hierarchy: position judgments were the most accurate, while angle and area were less reliable---insights that continue to influence data visualization design today.
[Did the experiment actually cover all 7 tasks??? Please be careful with how you cite these, and provide more detail -- that's what we're specifically looking for here.]{.svp}

\mt{They conducted a foundational study to assess how accurately people interpret different graphical encodings. They focused on six basic graphical perception tasks: position along a common scale, position along non-aligned scales, length, angle, slope, and area (represented by circles and irregular "blobs").
Participants were shown 70 visual displays, each with one standard object and three comparisons, and asked to estimate each comparison as a percentage of the standard.
The study involved 127 participants---high school students, college students, and professionals---who each made 210 judgments across all task types and standard sizes.
Stimuli were randomized to avoid learning effects}

The main outcome was estimation accuracy---how close each response was to the true percentage.
No scales or measurement tools were provided, so judgments relied purely on visual perception.
Each of the six tasks was tested with both small and large reference standards, and values ranged from 17.5% to 87.5%.
Results revealed a clear perceptual hierarchy: position along a common scale led to the most accurate estimates, followed by length.
In contrast, angle and area judgments were significantly less accurate.
These findings have had a lasting impact on visualization design, encouraging the use of perceptually stronger encodings for quantitative data.}

@simkin1987information investigated how different graphical encodings---position, length, and angle---affect performance on visual judgment tasks.
200 Undergraduate participants were shown pie charts, bar charts, and divided bar charts and asked to make either comparison judgments ($A/B$) or proportion-of-the-whole ($A/(A+B)$) judgements.
Each graph type relied on a different visual code: bar charts used position, divided bars used length, and pie charts used angle.
Participants completed 90 trials under timed conditions.
Results showed that position and length led to higher accuracy and faster response times for comparison tasks, while pie charts supported better performance in proportion-of-the-whole judgments, demonstrating a clear interaction between graph type and task type.

Very recently, more works have been discovered on this debate that caught researchers' eyes on the topic.
@skau2016arcs investigated how common distortions in pie charts affect judgment accuracy.
Participants were shown a series of pie chart variations and asked to estimate the percentage represented by a highlighted slice.
The variations included a standard pie chart, an "exploded" pie (with a slice offset), a "larger slice" chart (with an extended radius), a vertically compressed elliptical pie, and a square-shaped chart.
All charts had two segments and were rotated randomly to eliminate positional bias.
Participants were recruited via Mechanical Turk and asked to provide whole-number estimates for values ranging from 3% to 97%.
Results showed that all distortions---except the exploded pie---led to significantly higher judgment errors compared to the baseline pie chart.


\mt{Skau and Kosara (2016) conducted a focused experiment to isolate how individual visual encodings---arc length, angle, and area---contribute to interpretation accuracy in pie and donut charts.
They created six chart types: baseline pie, baseline donut, arc-only, angle (pie-style), angle (donut-style), and area-only.
Each chart showed just two segments---a blue "target" slice and a gray remainder---allowing participants to focus on estimating a single proportion without distractions.
Across 48 randomized trials (eight per chart type), 100 Mechanical Turk participants were asked the same question for every chart: "What percentage of the whole is indicated below?" The charts were randomly rotated to avoid alignment biases, and a brief tutorial was provided to ensure participants understood each chart forma} 

Measurement & Accuracy The study focused exclusively on perceptual accuracy.
For each chart, researchers measured the absolute difference between the participant's estimate and the true value, as well as error patterns such as reversed judgments (e.g., answering 75% instead of 25% on angle charts).
No time constraints were enforced, and response time or subjective preferences were not formally recorded.
However, participants were asked before and after the main task which visual cue they believed they relied on---arc, angle, or area.
Results revealed that baseline pie charts led to the most accurate judgments overall, followed by arc-only encodings.
Surprisingly, many participants reported using angle judgments, even in chart types where angle cues were removed or degraded.}

@hill2025bar did the study that involved three online experiments designed to evaluate how effectively bar, pie, and donut charts support part-whole estimation and ranking tasks.
In Experiment 1, participants viewed randomized sets of charts (10 bar, 5 pie, 5 donut) created from multinomially generated data and answered ranking and proportion estimation questions.
Experiment 2 focused on charts where elements A and B were similar in size, allowing for precise comparison of visual discrimination accuracy across chart types.
Experiment 3 assessed relative magnitude estimation on pie and donut charts using a direct comparison task ("If A is 100, what is B?").
A total of 42 participants from the University of Surrey took part in the study via Qualtrics, and all data were anonymized

## Criticism of previous experimental design

@eellsRelativeMeritsCircles1926 study offered significant preliminary insights on the perception of proportions through pie and bar charts; yet, it possesses multiple drawbacks.  While Von Hun has already identified several limits in his paper, further ones warrant discussion.  The sample comprised exclusively psychology students from one institution, hence introducing potential sampling bias and constraining generalisability.  Secondly, the design failed to mitigate the sequence of chart types – participants were exposed to pie charts initially, followed by bar charts three days later, potentially introducing learning or memory effects that could skew the comparison in favor of bar charts.  Third, although participants reported their estimation tactics post hoc (e.g., angle, area), no measures were taken during the task (such as eye tracking or time consumed per chart), which reduces the capacity to analyse the underlying cognitive mechanisms.  Ultimately, the study exclusively assessed whole-number estimates, perhaps obscuring nuanced variations in accuracy or bias among chart styles.

@spenceDisplayingProportionsPercentages1991 demonstrated that pie charts can outperform bar charts under certain conditions when displaying proportions.
They conducted a series of four experiments, each providing consistent insights into the comparative effectiveness of pie charts and bar charts for various tasks involving the interpretation of proportions.

The first experiment investigated how people process pie charts, bar charts, and horizontal divided bar charts by measuring accuracy, processing time, and the effect of the number of components.
Thirty participants were divided into three groups based on task type: simple comparison ($A$ vs. $B$), comparison of a single value with a sum ($A$ vs. $B + C$), and comparison of two sums ($A + B$ vs. $C + D$).

\svp{Were participants estimating ratios, or just judging larger/smaller?}. \mt{Participants were not assessing ratios; they were rendering binary judgements regarding which component (or combination of components) was greater. The experiment employed a two-alternative forced-choice (2AFC) design, in which participants identified the greater of two possibilities (e.g., $A$ vs. $B$, or $A + B$ vs. $C + D$). Instead of conducting numerical estimation or ratio calculation, they compare relative magnitude.}
Accuracy improved with longer display times, reaching near 100% for simple tasks and around 90% for complex ones. Bar charts performed slightly better than pie charts for simple comparisons under time pressure, but differences between chart types were negligible for complex tasks.

[Were participants estimating ratios, or just judging larger/smaller?]{.svp} Accuracy improved with longer display times, reaching near 100% for simple tasks and around 90% for complex ones.
Bar charts performed slightly better than pie charts for simple comparisons under time pressure, but differences between chart types were negligible for complex tasks.

The second experiment yielded similar results but employed a different approach.
It introduced a table instead of a horizontal bar chart, fixed the processing time at 3.0 seconds, reduced the number of component levels, and adopted a within-subject design for tasks.
Additionally, it tested the effect of ordering components by magnitude.
The results confirmed the superiority of bar charts over pie charts for accuracy, particularly for simpler tasks and fewer components.
However, the lack of an ordering effect challenges the common belief that ordered components improve perception.

\svp{How many categories were used? It's possible that this is true for small tables but not as true for larger tables.}
\mt{The experiment included two categorical levels: four and seven components. The limited quantity likely facilitated the lack of an ordering effect, since participants could readily compare values without reliance on positional signals. In larger tables with more components, ordering may significantly enhance the accuracy and efficiency of interpretation.}

[How many categories were used? It's possible that this is true for small tables but not as true for larger tables.]{.svp}

The third experiment examined how task complexity and display type (pie chart, bar chart, and table) affect performance using a within-subject design, where each subject performed all three task types.
Unlike Experiment 1, which used a between-subjects design, and Experiment 2, which introduced tables and fixed processing time, Experiment 3 retained pie charts, bar charts, and tables while excluding the horizontal divided bar chart.
Processing time was fixed at 3.0 seconds [You can fix stimulus time but not processing time -- processing takes as long as it takes]{.svp}, and two levels of components (4 and 7) were tested.
Accuracy declined with task complexity, and while pie and bar charts showed similar performance for simpler tasks, pie charts outperformed the others for complex tasks, likely due to easier component identification and combination.
Adjacency influenced bar chart performance but not pie charts, suggesting that perceptual and cognitive factors favor pie charts for complex tasks.

The fourth experiment tested whether color coding could enhance performance by simplifying component identification.
The design was identical to Experiment 3, except components were color-coded (red or blue) instead of using alphabetical labels.
Processing time was reduced to 1.0 second since the task was expected to be easier with color cues.
Accuracy was higher for pie (86%) and bar (84%) charts than for tables (75%), with performance declining as task complexity increased (88%, 82%, and 76% for simple to complex tasks).
Unlike previous experiments, the number of components had no effect on accuracy, suggesting that once components were easily located through color, cognitive comparison was unaffected by complexity.
Similar to Experiment 3, pie charts outperformed bar charts for complex tasks, but bar charts were better for simpler tasks.
This indicates that color coding can improve performance in complex charts by simplifying component identification.

The experiment has several limitations.
The small and homogeneous sample (mainly students) limits the generalizability of the findings.

Short exposure times (1.0--6.0 seconds) may not reflect real-world scenarios where viewers have more time to process information.\mt{Might delete this paragraph}

\svp{Why do psycologists use short exposure times? Look into this -- there's a reason} The artificial setting (controlled computer-based tests) fails to capture real-world variability, such as distractions and viewing distance.\mt{Psychologists employ brief exposure durations (often 1–6 seconds) to concentrate on rapid perceptual reactions rather than advanced cognitive processing. This ensures that participants depend on visual perception rather than memory or intentional comparison. Foundational research, shown by @clevelandGraphicalPerceptionTheory1984, employed brief display durations to elicit direct assessments of visual attributes.}

Short exposure times (1.0--6.0 seconds) may not reflect real-world scenarios where viewers have more time to process information.
[Why do psycologists use short exposure times? Look into this -- there's a reason]{.svp} The artificial setting (controlled computer-based tests) fails to capture real-world variability, such as distractions and viewing distance.
Reducing exposure time to 1.0 second in Experiment 4 may have biased results toward pie charts by encouraging intuitive rather than analytical processing

# Measurement and Preference

@eellsRelativeMeritsCircles1926 didn't just look at how well people performed---he also explored how they felt about the charts and how they approached the task.
When it came to accuracy, pie charts actually did better than bar charts, especially as the number of segments increased.
People also tended to move a bit faster with pie charts, completing slightly more within five minutes.
[Eells didn't do the hypothesis test -- can you from provided information? Was it significant? Be careful about uncritically reporting results.]{.svp} One of the most striking findings was that bar charts led to 70% more large errors, making them less reliable for precise judgment.
After the task, students were asked which chart type they preferred, and the majority chose pie charts for showing part-whole data.
When it came to strategy, most students said they judged the slices using arc length, with others using angles or area---and all three methods turned out to be about equally accurate.
Overall, the results challenged the common criticism that pie charts are hard to read.


# Result

Which chart works best really depends on the task.
When people are asked to simply compare two values (A vs B), bar charts consistently come out on top---they're faster and more accurate, and participants tend to prefer them for that reason (@spenceDisplayingProportionsPercentages1991; @simkin1987information; @hill2025bar).

When the task shifts to estimating what proportion one part is of the whole ($A / (A+B)$), pie charts do better, likely because they align with how we naturally think about part-whole relationships (@clevelandGraphicalPerceptionTheory1984; @simkin1987information).
\svp{Is this still true when A and B aren't adjacent in e.g. a 3-4 component chart?} \mt{While pie charts have been shown to support accurate part-to-whole estimations in two-part visualizations (e.g., A and B as adjacent slices), it is unclear whether this advantage persists in more complex charts. When pie charts include three or more segments, and the parts being compared (e.g., A and B) are not adjacent, the viewer must shift focus across non-contiguous regions of the circle. This added perceptual effort may diminish the intuitive advantage typically associated with pie charts in simpler tasks. Further studies are needed to assess whether the part-whole encoding remains effective when the target slices are visually separated—especially in 3- or 4-component pie charts where holistic comparison becomes less direct}

When the task shifts to estimating what proportion one part is of the whole ($A / (A+B)$), pie charts do better, likely because they align with how we naturally think about part-whole relationships (Cleveland & McGill, 1984; Simkin & Hastie, 1987).
[Is this still true when A and B aren't adjacent in e.g. a 3-4 component chart?]{.svp} [While pie charts have been shown to support accurate part-to-whole estimations in two-part visualizations (e.g., A and B as adjacent slices), it is unclear whether this advantage persists in more complex charts. When pie charts include three or more segments, and the parts being compared (e.g., A and B) are not adjacent, the viewer must shift focus across non-contiguous regions of the circle. This added perceptual effort may diminish the intuitive advantage typically associated with pie charts in simpler tasks. Further studies are needed to assess whether the part-whole encoding remains effective when the target slices are visually separated—especially in 3- or 4-component pie charts where holistic comparison becomes less direct]{.mt}


For more complex comparisons---like $A$ vs $B+C$ or $A+B$ vs $C+D$, the results are more mixed.
Bar charts have a slight edge when comparing a single value to a sum ($A$ vs $B+C$), but when comparing two grouped values ($A+B$ vs $C+D$), pie charts actually perform better @spenceDisplayingProportionsPercentages1991.
This might be because it's easier to visually group adjacent slices than non-aligned bars (@skau2016arcs).

When it comes to ranking multiple parts, like identifying the top three largest values, bar charts win again, as their alignment allows for quicker visual scanning (@hill2025bar; @skau2016arcs).
And in magnitude estimation tasks (e.g., "If A is 100, what is B?"), pie charts tend to outperform bars, though people are more likely to misjudge values slightly in those formats (@skau2016arcs; @hill2025bar).

In the end, there's no universal winner---the best chart depends on the specific task and what kind of judgment you're asking the reader to make.

## Comparison table

```{r}
#| echo: false
library(knitr)
library(tibble)

# Data with Study_Label and Preference column
study_table <- tribble(
  ~Study_Label, ~Study_Type,       ~Comparison, ~Question,                     ~Measure,                        ~Participants,          ~Trials_per_Participant,       ~Preference,
  "A-exp1",     "Eells (1926)",    "A / (A+B+...)", "Estimate each segment",       "Accuracy, Preference",          "97 psychology students", "15 (Pie + Bar; no repeat)",   "Pie",
  "A-exp2",     "Croxton (1927)",  "A / (A+B)", "Estimate percentage values",  "Accuracy",                      "807 students",           "27 (bar & pie mixed)",        "Pie",
  "B-exp1",     "Von Huhn (1927)", "A / B",     "What is B if A is 1?",        "Accuracy",                      "287 participants",       "2 ratios × 2 chart types",    "Bar",
  "B-exp2",     "Spence (1991)",   "A, A+B, etc.","Which part is largest?",   "Accuracy, Speed",               "Varied (online)",        "Not specified",               "Bar",
  "C-exp1",     "Petersen (1954)", "A / (A+B)", "Estimate proportion",         "Accuracy",                      "86 air force personnel", "3440 responses total",        "Bar",
  "D-exp1",     "Cleveland (1986)","A / (A+B)", "What % is this of standard?", "Accuracy",                      "127 (HS, college, tech)", "210 (6 task types)",          "Bar",
  "E-exp1",     "Simkin & Hastie (1987)", "A / B & A / (A+B)", "Compare or estimate", "Accuracy, Time",       "200 undergraduates",      "90 (timed)",                  "Pie (for A/(A+B))",
  "F-exp1",     "Skau & Kosara (2016)", "A / (A+B)", "What % is the blue part?", "Accuracy",                   "100 MTurk",              "48 (6 chart types × 8)",      "Pie",
  "G-exp1",     "Hill (2025)",     "Ranking, A vs B, A+B", "Rank or estimate", "Accuracy",                     "42 Univ. of Surrey",     "3 experiments",               "Bar"
)

# Display table
kable(
  study_table[, c("Study_Label", "Study_Type", "Comparison", "Question", "Measure", "Participants", "Trials_per_Participant", "Preference")],
  col.names = c("Label", "Citation", "Comparison", "Question", "Measure", "Participants", "Trials/Participant", "Preference"),
  caption = "Summary of Experimental Studies on Chart Perception"
)

```


## Summary: When to Use Each Chart Type

| **Use**              | **When**                                                              |
|----------------------|-----------------------------------------------------------------------|
| **Bar charts**       | Comparing individual parts (A vs B), ranking, or scanning many values |
| **Pie charts**       | Estimating proportions of a whole ( A / (A + B)) with few components  |
| **Avoid pie charts** | When comparing non-adjacent slices or judging small differences       |

# Conclusion

As of now, no one has determined a definitive winner between pie charts and bar charts.
These two charts remain essential in every part of science, business, sociology, and related fields.
The efficacy of various charts is contingent upon ratio, measurement, and perception aspects of the representation.
In research, a chart should not be dismissed solely because it is deemed inadequate.
Pie charts make it easier to assess proportions relative to the whole, but bar charts excel in comparing magnitudes and ranking activities.
Performance fluctuates depending on whether the task entails value estimation, segment comparison, or identification of the major component.
Generally, charts that clearly delineate comparative parts (e.g., adjacent slices or bold outlines) enhance interpretability.

We have also discovered an intriguing fact that, despite the evolution of formats and digital interfaces, fundamental perceptual concepts (@eellsRelativeMeritsCircles1926, @clevelandGraphicalPerceptionTheory1984 and so on) continue to have validity.
Nonetheless, this finding does not signify the conclusion of the pursuit for the optimal chart.
Future research can clarify the dispute through improved experimental design and more compelling methodologies.

# Future Research

Numerous constraints are present in both early and contemporary investigations.
Initial trials (from the 1920s to 1980s) frequently exhibited insufficient statistical rigor, characterized by delicate measurement frameworks and rudimentary designs.
Contemporary research (@spenceDisplayingProportionsPercentages1991; @hill2025bar) has implemented enhanced experimental designs, however it continues to encounter difficulties, especially with participant diversity.

Contemporary research predominantly utilizes student samples, so constraining generalizability and potentially failing to represent wider perceptual disparities across age, education, or cultural contexts.
Subsequent investigations ought to tackle this issue by enhancing sample variety and refining experimental methodologies.
This may reveal fresh insights and promote more inclusive, contextually suitable chart type.

Individuals' perceptions of charts may alter between devices---mobile phones, tablets, or desktop monitors---due to variations in screen size, resolution, and interaction methods.
Furthermore, enhancing the reliability of perceptual measurements is crucial.
Future research may include technologies such as eye-tracking, response time analysis, or cognitive load evaluations to provide more nuanced findings.
The objective is to convert experimental results into practical design advice that assist practitioners in choosing the most suitable chart kinds for certain audiences and jobs.

# Reference
